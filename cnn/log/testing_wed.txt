tensor([False, False,  True,  True])
>>> i
9
>>> c
tensor([False, False,  True,  True])
>>> c[0]
tensor(False)
>>> c[0].item()
False
>>> predicted
tensor([4, 4, 9, 9])
>>> local_label
tensor(9)
>>> class_correct
[45.0, 97.0, 64.0, 67.0, 46.0, 56.0, 68.0, 79.0, 73.0, 80.0]
>>> class_correct[local_label]
80.0
>>> c[0]
tensor(False)
>>> predicted
tensor([4, 4, 9, 9])
>>> predicted[0].item()
4
>>> local_labels
tensor([9, 9, 9, 9])
>>> local_labels[0].item()
9
>>> class_predict = []
>>> class_true = []
>>> class_correct = list(0. for i in range(num_species))
>>> class_total = list(0. for i in range(num_species))
>>> with torch.no_grad():
...     for local_data in testloader:
...             # get samples and labels
...             local_batch, local_labels = local_data
...             # Transfer to GPU
...             local_batch, local_labels = local_batch.to(device), local_labels.to(device)
...
 %%' % (
        species_list[i], 100 * class_correct[i] / class_total[i]))

print('Overall accuracy on test set')
print('%d %%' % (100 * sum(class_correct) / sum(class_total)))

print('Confusion Matrix')
cf_m = confusion_matrix(class_predict, class_true)
print(cf_m)
^CTraceback (most recent call last):
  File "<stdin>", line 2, in <module>
  File "/home-4/xwang145@jhu.edu/.conda/envs/metagenomics/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 345, in __next__
    data = self._next_data()
  File "/home-4/xwang145@jhu.edu/.conda/envs/metagenomics/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 841, in _next_data
    idx, data = self._get_data()
  File "/home-4/xwang145@jhu.edu/.conda/envs/metagenomics/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 808, in _get_data
    success, data = self._try_get_data()
  File "/home-4/xwang145@jhu.edu/.conda/envs/metagenomics/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 761, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home-4/xwang145@jhu.edu/.conda/envs/metagenomics/lib/python3.7/multiprocessing/queues.py", line 104, in get
    if not self._poll(timeout):
  File "/home-4/xwang145@jhu.edu/.conda/envs/metagenomics/lib/python3.7/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home-4/xwang145@jhu.edu/.conda/envs/metagenomics/lib/python3.7/multiprocessing/connection.py", line 414, in _poll
    r = wait([self], timeout)
  File "/home-4/xwang145@jhu.edu/.conda/envs/metagenomics/lib/python3.7/multiprocessing/connection.py", line 920, in wait
    ready = selector.select(timeout)
  File "/home-4/xwang145@jhu.edu/.conda/envs/metagenomics/lib/python3.7/selectors.py", line 415, in select
    fd_event_list = self._selector.poll(timeout)
KeyboardInterrupt
>>> from sklearn.metrics import confusion_matrix
>>> class_predict = []
>>> class_true = []
>>> class_correct = list(0. for i in range(num_species))
>>> class_total = list(0. for i in range(num_species))
>>> with torch.no_grad():
...     for local_data in testloader:
...             local_batch, local_labels = local_data
...             local_batch, local_labels = local_batch.to(device), local_labels.to(device)
...             outputs = net(local_batch.float())
...             _, predicted = torch.max(outputs, 1)
...             c = (predicted == local_labels).squeeze()
...             for i in range(4):
...                     local_label = local_labels[i]
...                     class_predict += predicted[i].item()
...                     class_true += local_labels[i].item()
...                     class_correct[local_label] += c[i].item()
...                     class_total[local_label] += 1
...
Traceback (most recent call last):
  File "<stdin>", line 10, in <module>
TypeError: 'int' object is not iterable
>>> Traceback (most recent call last):
  File "/home-4/xwang145@jhu.edu/.conda/envs/metagenomics/lib/python3.7/multiprocessing/queues.py", line 242, in _feed
    send_bytes(obj)
  File "/home-4/xwang145@jhu.edu/.conda/envs/metagenomics/lib/python3.7/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/home-4/xwang145@jhu.edu/.conda/envs/metagenomics/lib/python3.7/multiprocessing/connection.py", line 404, in _send_bytes
    self._send(header + buf)
  File "/home-4/xwang145@jhu.edu/.conda/envs/metagenomics/lib/python3.7/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/home-4/xwang145@jhu.edu/.conda/envs/metagenomics/lib/python3.7/multiprocessing/queues.py", line 242, in _feed
    send_bytes(obj)
  File "/home-4/xwang145@jhu.edu/.conda/envs/metagenomics/lib/python3.7/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/home-4/xwang145@jhu.edu/.conda/envs/metagenomics/lib/python3.7/multiprocessing/connection.py", line 404, in _send_bytes
    self._send(header + buf)
  File "/home-4/xwang145@jhu.edu/.conda/envs/metagenomics/lib/python3.7/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe

>>> local_label
tensor(0)
>>> class_correct
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
>>> type(class_correct)
<class 'list'>
>>> class_predict = []
>>> class_true = []
>>> class_correct = list(0. for i in range(num_species))
>>> class_total = list(0. for i in range(num_species))
>>> with torch.no_grad():
...     for local_data in testloader:
...             local_batch, local_labels = local_data
...             local_batch, local_labels = local_batch.to(device), local_labels.to(device)
...             outputs = net(local_batch.float())
...             _, predicted = torch.max(outputs, 1)
...             c = (predicted == local_labels).squeeze()
...             for i in range(4):
...                     local_label = local_labels[i]
...                     class_predict.append(predicted[i].item())
...                     class_true.append(local_labels[i].item())
...                     class_correct[local_label] += c[i].item()
...                     class_total[local_label] += 1
...
>>> print('Accuracy by class')
Accuracy by class
>>> for i in range(num_species):
...     print('%5s : %2d %%' % (
...         species_list[i], 100 * class_correct[i] / class_total[i]))
...
NC_010117 : 45 %
NC_023013 : 97 %
NC_014374 : 64 %
NC_009515 : 67 %
NC_018621 : 46 %
NC_008698 : 56 %
NC_020246 : 68 %
NZ_LN832404 : 79 %
NC_004113 : 73 %
NC_014494 : 80 %
>>> print('Overall accuracy on test set')
Overall accuracy on test set
>>> print('%d %%' % (100 * sum(class_correct) / sum(class_total)))
67 %
>>>
>>> print('Confusion Matrix')
Confusion Matrix
>>> cf_m = confusion_matrix(class_predict, class_true)
>>> print(cf_m)
[[45  0  0  1  0  0  0  2  0  0]
 [ 0 97 14  0  0 33  0  3  3  0]
 [ 0  0 64  0  0  5  2  2  0  0]
 [ 1  0  0 67  0  0  2  0  0  4]
 [ 2  0  0  2 46  0 20  0  0  8]
 [ 0  3 19  0  5 56  0  1  2  1]
 [ 0  0  0  7  0  0 68  1  0  2]
 [46  0  2  0  2  0  0 79 21  3]
 [ 1  0  0  0  0  6  0 11 73  2]
 [ 5  0  1 23 47  0  8  1  1 80]]
>>> cnn_dir
'/work-zfs/mschatz1/xwang145/data/cnn/read_1000_error_1'
>>> cf_m.shape
(10, 10)
>>> cnn_dir
'/work-zfs/mschatz1/xwang145/data/cnn/read_1000_error_1'
>>> cnn_dir
'/work-zfs/mschatz1/xwang145/data/cnn/read_1000_error_1'
>>> os.path.join(cnn_dir,'confusion_matrix.npy')
'/work-zfs/mschatz1/xwang145/data/cnn/read_1000_error_1/confusion_matrix.npy'
>>> print('saved to', cf_m_file)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
NameError: name 'cf_m_file' is not defined
>>> cf_m_fie = os.path.join(cnn_dir,'confusion_matrix.npy')
>>> print('saved to', cf_m_file)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
NameError: name 'cf_m_file' is not defined
>>> cf_m_file = os.path.join(cnn_dir,'confusion_matrix.npy')
>>> print('saved to', cf_m_file)
saved to /work-zfs/mschatz1/xwang145/data/cnn/read_1000_error_1/confusion_matrix.npy
>>> cnn_model_file
'/work-zfs/mschatz1/xwang145/data/cnn/read_1000_error_1/cnn_epoch_0.i_109999.pth'
>>> os.path.basename(cnn_model_file)
'cnn_epoch_0.i_109999.pth'
>>> os.path.join(cnn_dir,'confusion_matrix' + os.path.basename(cnn_model_file) + '.npy')
'/work-zfs/mschatz1/xwang145/data/cnn/read_1000_error_1/confusion_matrixcnn_epoch_0.i_109999.pth.npy'
>>> os.path.join(cnn_dir,'confusion_matrix.' + os.path.basename(cnn_model_file) + '.npy')
'/work-zfs/mschatz1/xwang145/data/cnn/read_1000_error_1/confusion_matrix.cnn_epoch_0.i_109999.pth.npy'
>>>
(metagenomics)[xwang145@jhu.edu@compute0753 cnn]$ python train.py /work-zfs/mschatz1/xwang145/data/long_reads/read_500_error_1 cnn_epoch_2.i_49999.pth
usage: train.py [-h] reads_dir
train.py: error: unrecognized arguments: cnn_epoch_2.i_49999.pth
(metagenomics)[xwang145@jhu.edu@compute0753 cnn]$
(metagenomics)[xwang145@jhu.edu@compute0753 cnn]$ python train.py /work-zfs/mschatz1/xwang145/data/long_reads/read_500_error_10 cnn_epoch_2.i_9999.pth
usage: train.py [-h] reads_dir
train.py: error: unrecognized arguments: cnn_epoch_2.i_9999.pth
(metagenomics)[xwang145@jhu.edu@compute0753 cnn]$
(metagenomics)[xwang145@jhu.edu@compute0753 cnn]$ python train.py /work-zfs/mschatz1/xwang145/data/long_reads/read_1000_error_1 cnn_epoch_1.i_19999.pth
usage: train.py [-h] reads_dir
train.py: error: unrecognized arguments: cnn_epoch_1.i_19999.pth
(metagenomics)[xwang145@jhu.edu@compute0753 cnn]$
(metagenomics)[xwang145@jhu.edu@compute0753 cnn]$ python test.py /work-zfs/mschatz1/xwang145/data/long_reads/read_500_error_1 cnn_epoch_2.i_49999.pth
Testing on 10000 reads
Opening long reads file: NC_010117.reads.1000bp.fa
Opening long reads file: NC_023013.reads.1000bp.fa
Opening long reads file: NC_014374.reads.1000bp.fa
Opening long reads file: NC_009515.reads.1000bp.fa
Opening long reads file: NC_018621.reads.1000bp.fa
Opening long reads file: NC_008698.reads.1000bp.fa
^CTraceback (most recent call last):
  File "test.py", line 63, in <module>
    testset = Dataset(reads_dir, reads_files, test_list, labels_dict, kmer_length, transform=transform)
  File "/home-net/home-4/xwang145@jhu.edu/code/MetagenomicsCNN/cnn/dataset.py", line 33, in __init__
    bioseq_list = list(SeqIO.parse(os.path.join(reads_dir,file),"fasta"))
  File "/home-4/xwang145@jhu.edu/.conda/envs/metagenomics/lib/python3.7/site-packages/Bio/SeqIO/FastaIO.py", line 186, in FastaIterator
    for title, sequence in SimpleFastaParser(handle):
  File "/home-4/xwang145@jhu.edu/.conda/envs/metagenomics/lib/python3.7/site-packages/Bio/SeqIO/FastaIO.py", line 70, in SimpleFastaParser
    lines.append(line.rstrip())
KeyboardInterrupt
(metagenomics)[xwang145@jhu.edu@compute0753 cnn]$ clear
(metagenomics)[xwang145@jhu.edu@compute0753 cnn]$ python test.py /work-zfs/mschatz1/xwang145/data/long_reads/read_500_error_1 cnn_epoch_2.i_49999.pth
Testing on 10000 reads
Opening long reads file: NC_010117.reads.1000bp.fa
Opening long reads file: NC_023013.reads.1000bp.fa
Opening long reads file: NC_014374.reads.1000bp.fa
Opening long reads file: NC_009515.reads.1000bp.fa
Opening long reads file: NC_018621.reads.1000bp.fa
Opening long reads file: NC_008698.reads.1000bp.fa
Opening long reads file: NC_020246.reads.1000bp.fa
Opening long reads file: NZ_LN832404.reads.1000bp.fa
Opening long reads file: NC_004113.reads.1000bp.fa
Opening long reads file: NC_014494.reads.1000bp.fa
Compute outputs
---------------
computed output on 200 reads
computed output on 400 reads
computed output on 600 reads
computed output on 800 reads
computed output on 1000 reads
computed output on 1200 reads
^CTraceback (most recent call last):
  File "test.py", line 90, in <module>
    print("---------------")
  File "/home-4/xwang145@jhu.edu/.conda/envs/metagenomics/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/home-net/home-4/xwang145@jhu.edu/code/MetagenomicsCNN/cnn/cnn.py", line 35, in forward
    x = self.pool(F.relu(self.conv1(x)))
  File "/home-4/xwang145@jhu.edu/.conda/envs/metagenomics/lib/python3.7/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/home-4/xwang145@jhu.edu/.conda/envs/metagenomics/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 345, in forward
    return self.conv2d_forward(input, self.weight)
  File "/home-4/xwang145@jhu.edu/.conda/envs/metagenomics/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 342, in conv2d_forward
    self.padding, self.dilation, self.groups)
KeyboardInterrupt
(metagenomics)[xwang145@jhu.edu@compute0753 cnn]$ clear
(metagenomics)[xwang145@jhu.edu@compute0753 cnn]$ git pull
remote: Enumerating objects: 7, done.
remote: Counting objects: 100% (7/7), done.
remote: Compressing objects: 100% (1/1), done.
remote: Total 4 (delta 3), reused 4 (delta 3), pack-reused 0
Unpacking objects: 100% (4/4), done.
From https://github.com/DottedGlass/MetagenomicsCNN
   7bb89aa..e4940b3  master     -> origin/master
Updating 7bb89aa..e4940b3
Fast-forward
 cnn/test.py | 13 +++++++++++--
 1 file changed, 11 insertions(+), 2 deletions(-)
(metagenomics)[xwang145@jhu.edu@compute0753 cnn]$ clear
(metagenomics)[xwang145@jhu.edu@compute0753 cnn]$ python test.py /work-zfs/mschatz1/xwang145/data/long_reads/read_500_error_1 cnn_epoch_2.i_49999.pth
Testing on 1000 reads per species
Testing on 10000 reads total
Opening long reads file: NC_004113.reads.500bp.fa
Opening long reads file: NC_020246.reads.500bp.fa
Opening long reads file: NC_023013.reads.500bp.fa
Opening long reads file: NC_014374.reads.500bp.fa
Opening long reads file: NC_014494.reads.500bp.fa
Opening long reads file: NC_008698.reads.500bp.fa
Opening long reads file: NC_009515.reads.500bp.fa
Opening long reads file: NC_018621.reads.500bp.fa
Opening long reads file: NZ_LN832404.reads.500bp.fa
Opening long reads file: NC_010117.reads.500bp.fa
Compute outputs
---------------
Accuracy by class
NC_004113 : 85 %
NC_020246 : 54 %
NC_023013 : 84 %
NC_014374 : 74 %
NC_014494 : 57 %
NC_008698 : 69 %
NC_009515 : 87 %
NC_018621 : 40 %
NZ_LN832404 : 65 %
NC_010117 : 78 %
Overall accuracy on test set
69 %
Confusion Matrix
saved to /work-zfs/mschatz1/xwang145/data/cnn/read_500_error_1/confusion_matrix.cnn_epoch_2.i_49999.pth.npy
[[855   6  26  40  28  89   0   6 155  34]
 [  0 543   1   8  43   1  21  55   2   0]
 [  2   0 842  38   0  36   0   0   3   0]
 [  1  12  28 740   4  86   1   4   9   0]
 [ 14 109   7   5 571  22  61 231  16  30]
 [  8   0  64 109   3 692   0   5   0   1]
 [  2 191   0   1 144   0 873  58  10  40]
 [  3  71   1   4  81   8   6 403   3   8]
 [ 76  50  30  42  62  58  16  80 652 100]
 [ 39  18   1  13  64   8  22 158 150 787]]
14/05/2020 01:49:29
14/05/2020 01:52:09
(metagenomics)[xwang145@jhu.edu@compute0753 cnn]$
(metagenomics)[xwang145@jhu.edu@compute0753 cnn]$ python test.py /work-zfs/mschatz1/xwang145/data/long_reads/read_500_error_10 cnn_epoch_2.i_9999.pth
Testing on 1000 reads per species
Testing on 10000 reads total
Opening long reads file: NC_004113.reads.500bp.fa
Opening long reads file: NC_020246.reads.500bp.fa
Opening long reads file: NC_014374.reads.500bp.fa
Opening long reads file: NC_023013.reads.500bp.fa
Opening long reads file: NC_014494.reads.500bp.fa
Opening long reads file: NC_009515.reads.500bp.fa
Opening long reads file: NC_008698.reads.500bp.fa
Opening long reads file: NZ_LN832404.reads.500bp.fa
Opening long reads file: NC_018621.reads.500bp.fa
Opening long reads file: NC_010117.reads.500bp.fa
Compute outputs
---------------
Accuracy by class
NC_004113 : 44 %
NC_020246 : 75 %
NC_014374 : 64 %
NC_023013 : 79 %
NC_014494 : 37 %
NC_009515 : 79 %
NC_008698 : 41 %
NZ_LN832404 : 69 %
NC_018621 : 28 %
NC_010117 : 51 %
Overall accuracy on test set
57 %
Confusion Matrix
saved to /work-zfs/mschatz1/xwang145/data/cnn/read_500_error_10/confusion_matrix.cnn_epoch_2.i_9999.pth.npy
[[442   1  13  19  11   0  29 129   1   8]
 [  5 756  22   3 260 154   7  16 370  28]
 [ 40   8 648  81   8   0 179  26   3   5]
 [ 30   0 106 794   2   0 258  14   0   0]
 [ 24  33   8   5 372  25  20  17 172  26]
 [  1 143   0   0 171 793   0  18  77 106]
 [ 16   1  89  59   6   0 417  16   5   2]
 [433  22 106  35  45   8  84 691  36 280]
 [  1  31   5   4  88  13   5   5 283  34]
 [  8   5   3   0  37   7   1  68  53 511]]
14/05/2020 01:52:12
14/05/2020 01:54:52
(metagenomics)[xwang145@jhu.edu@compute0753 cnn]$
(metagenomics)[xwang145@jhu.edu@compute0753 cnn]$ python test.py /work-zfs/mschatz1/xwang145/data/long_reads/read_1000_error_1 cnn_epoch_1.i_19999.pth
Testing on 1000 reads per species
Testing on 10000 reads total
Opening long reads file: NC_010117.reads.1000bp.fa
Opening long reads file: NC_023013.reads.1000bp.fa
Opening long reads file: NC_014374.reads.1000bp.fa
Opening long reads file: NC_009515.reads.1000bp.fa
Opening long reads file: NC_018621.reads.1000bp.fa
Opening long reads file: NC_008698.reads.1000bp.fa
Opening long reads file: NC_020246.reads.1000bp.fa
Opening long reads file: NZ_LN832404.reads.1000bp.fa
Opening long reads file: NC_004113.reads.1000bp.fa
Opening long reads file: NC_014494.reads.1000bp.fa
Compute outputs
---------------
Accuracy by class
NC_010117 : 80 %
NC_023013 : 91 %
NC_014374 : 74 %
NC_009515 : 89 %
NC_018621 : 75 %
NC_008698 : 75 %
NC_020246 : 71 %
NZ_LN832404 : 72 %
NC_004113 : 75 %
NC_014494 : 64 %
Overall accuracy on test set
77 %
Confusion Matrix
saved to /work-zfs/mschatz1/xwang145/data/cnn/read_1000_error_1/confusion_matrix.cnn_epoch_1.i_19999.pth.npy
[[809   0   0   1  19   0   0 100   8   9]
 [  0 914  60   0   0 142   0   8  13   0]
 [  0  18 745   0   0  43   5   3   0   0]
 [ 30   0   0 895  20   0  56  10   1 119]
 [ 43   2   1  12 756   5 125  13   3 172]
 [  0  43 145   0   3 756   6   5  17   6]
 [  2   0   6  28  34   1 716   6   1  25]
 [ 74  12  26   0   9  14   5 721 199   6]
 [  6   7  14   1   0  30   2 127 751  14]
 [ 36   4   3  63 159   9  85   7   7 649]]
14/05/2020 01:54:54
14/05/2020 02:04:16
(metagenomics)[xwang145@jhu.edu@compute0753 cnn]$
(metagenomics)[xwang145@jhu.edu@compute0753 cnn]$ python test.py /work-zfs/mschatz1/xwang145/data/long_reads/read_1000_error_10 cnn_epoch_1.i_49999.pth
Testing on 1000 reads per species
Testing on 10000 reads total
Opening long reads file: NC_020246.reads.1000bp.fa
Opening long reads file: NC_008698.reads.1000bp.fa
Opening long reads file: NC_014494.reads.1000bp.fa
Opening long reads file: NC_004113.reads.1000bp.fa
Opening long reads file: NZ_LN832404.reads.1000bp.fa
Opening long reads file: NC_009515.reads.1000bp.fa
Opening long reads file: NC_018621.reads.1000bp.fa
Opening long reads file: NC_010117.reads.1000bp.fa
Opening long reads file: NC_023013.reads.1000bp.fa
Opening long reads file: NC_014374.reads.1000bp.fa
Compute outputs
---------------
Accuracy by class
NC_020246 : 70 %
NC_008698 : 50 %
NC_014494 : 64 %
NC_004113 : 72 %
NZ_LN832404 : 73 %
NC_009515 : 78 %
NC_018621 : 54 %
NC_010117 : 46 %
NC_023013 : 87 %
NC_014374 : 69 %
Overall accuracy on test set
66 %
Confusion Matrix
saved to /work-zfs/mschatz1/xwang145/data/cnn/read_1000_error_10/confusion_matrix.cnn_epoch_1.i_49999.pth.npy
[[707   1  56   1  11  98  88   7   2   3]
 [  0 506   4   4   2   0   1   0  44  43]
 [106  23 645  17  20  66 268  38   3   5]
 [  4  66  11 723 189   1   1   6  31  32]
 [ 10  75  42 231 731   7  40 411   9  65]
 [ 60   0  78   0   6 782  14  26   0   0]
 [ 99   4 139   2   6  25 548  44   2   3]
 [  1   0  20   0  21  21  39 468   0   0]
 [  0 239   1  17   5   0   1   0 876 151]
 [ 13  86   4   5   9   0   0   0  33 698]]
14/05/2020 02:04:18
14/05/2020 02:13:59
(metagenomics)[xwang145@jhu.edu@compute0753 cnn]$
(metagenomics)[xwang145@jhu.edu@compute0753 cnn]$ echo "Done"salloc: Job 44233877 has exceeded its time limit and its allocation has been revoked.
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
srun: error: compute0753: task 0: Killed
srun: Terminating job step 44233877.0
(3.7.4)[xwang145@jhu.edu@bc-login01 cnn]$ interact -c 6 -t 6:0:0 -p express
Tasks:    1
Cores/task: 6
Total cores: 6
Walltime: 6:0:0
Reservation:
Queue:    express
Command submitted: salloc -J interact -N 1-1 -n 1 -c 6 --time=6:0:0 -p express srun --pty bash
salloc: Granted job allocation 44253098
+----------------------------------------------------------------+
|   Group Balance. Use 'sbalance' or 'sbalance -f' to see more   |
+-----------+---------------+---------------+---------+----------+
|   Account | User/NumUsers | Allocation(h) | Used(h) | Usage(%) |
+-----------+---------------+---------------+---------+----------+
| abattle4* |            38 |        250000 |   31703 |    12.68 |
|  mschatz1 |            40 |        600000 |   20362 |     3.39 |
+-----------+---------------+---------------+---------+----------+
+--------------------------------------------+
|  $HOME quota: login is disabled when full  |
+-------------+-------------+----------------+
|    Usage GB |      Max GB |   Last Updated |
+-------------+-------------+----------------+
|       2.274 |      50.000 |        11:44AM |
+-------------+-------------+----------------+
+--------------------------------------------------------------------------------------------+
|   Scratch quota: group mschatz1. Last Update: 10:02AM. Use 'scratchquota -f' to see more   |
+------------------------+----------------+----------------+----------------+----------------+
|         Group/Username |       Usage TB |         Max TB |          Files |      Max Files |
+------------------------+----------------+----------------+----------------+----------------+
|               mschatz1 |         46.731 |         90.000 |       86680307 |      314572800 |
|       xwang145@jhu.edu |          0.198 |              - |           6974 |              - |
+------------------------+----------------+----------------+----------------+----------------+
(3.7.4)[xwang145@jhu.edu@compute0753 cnn]$ exit
exit
salloc: Relinquishing job allocation 44253098
(3.7.4)[xwang145@jhu.edu@bc-login01 cnn]$ interact -c 6 -t 6:0:0 -p express
Tasks:    1
Cores/task: 6
Total cores: 6
Walltime: 6:0:0
Reservation:
Queue:    express
Command submitted: salloc -J interact -N 1-1 -n 1 -c 6 --time=6:0:0 -p express srun --pty bash
salloc: Granted job allocation 44253099
+----------------------------------------------------------------+
|   Group Balance. Use 'sbalance' or 'sbalance -f' to see more   |
+-----------+---------------+---------------+---------+----------+
|   Account | User/NumUsers | Allocation(h) | Used(h) | Usage(%) |
+-----------+---------------+---------------+---------+----------+
| abattle4* |            38 |        250000 |   31703 |    12.68 |
|  mschatz1 |            40 |        600000 |   20362 |     3.39 |
+-----------+---------------+---------------+---------+----------+
+--------------------------------------------+
|  $HOME quota: login is disabled when full  |
+-------------+-------------+----------------+
|    Usage GB |      Max GB |   Last Updated |
+-------------+-------------+----------------+
|       2.274 |      50.000 |        11:44AM |
+-------------+-------------+----------------+
+--------------------------------------------------------------------------------------------+
|   Scratch quota: group mschatz1. Last Update: 10:02AM. Use 'scratchquota -f' to see more   |
+------------------------+----------------+----------------+----------------+----------------+
|         Group/Username |       Usage TB |         Max TB |          Files |      Max Files |
+------------------------+----------------+----------------+----------------+----------------+
|               mschatz1 |         46.731 |         90.000 |       86680307 |      314572800 |
|       xwang145@jhu.edu |          0.198 |              - |           6974 |              - |
+------------------------+----------------+----------------+----------------+----------------+
(3.7.4)[xwang145@jhu.edu@compute0753 cnn]$
